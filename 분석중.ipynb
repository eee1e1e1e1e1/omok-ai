{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "human_play.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle\n",
    "from game import Board, Game\n",
    "#from mcts_pure import MCTSPlayer as MCTS_Pure    # 순수 MCTS\n",
    "from mcts_alphaZero import MCTSPlayer           # 변형된 MCTS\n",
    "from policy_value_net_numpy import PolicyValueNetNumpy\n",
    "# from policy_value_net import PolicyValueNet  # Theano and Lasagne\n",
    "# from policy_value_net_pytorch import PolicyValueNet  # Pytorch\n",
    "# from policy_value_net_tensorflow import PolicyValueNet # Tensorflow\n",
    "# from policy_value_net_keras import PolicyValueNet  # Keras\n",
    "\n",
    "class Human(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.player = None\n",
    "\n",
    "    def set_player_ind(self, p):\n",
    "        self.player = p\n",
    "\n",
    "    def get_action(self, board):\n",
    "        try:\n",
    "            location = input(\"Your move: \")\n",
    "            if isinstance(location, str) : location = [int(n, 10) for n in location.split(\",\")]\n",
    "            move = board.location_to_move(location)\n",
    "        except Exception as e : move = -1\n",
    "            \n",
    "        if move == -1 or move not in board.availables:\n",
    "            print(\"invalid move\")\n",
    "            move = self.get_action(board)\n",
    "            \n",
    "        return move\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Human {}\".format(self.player)\n",
    "\n",
    "\n",
    "def run():\n",
    "    n = 5\n",
    "    width, height = 8, 8\n",
    "    model_file = 'best_policy_8_8_5.model'\n",
    "    try:\n",
    "        board = Board(width=width, height=height, n_in_row=n)\n",
    "        game = Game(board)\n",
    "\n",
    "        # 학습된 policy_value_net를 불러온다. (Theano/Lasagne, PyTorch or TensorFlow)\n",
    "        # best_policy = PolicyValueNet(width, height, model_file = model_file)\n",
    "        # mcts_player = MCTSPlayer(best_policy.policy_value_fn, c_puct=5, n_playout=400)\n",
    "\n",
    "        # load the provided model (trained in Theano/Lasagne) into a MCTS player written in pure numpy\n",
    "        try: policy_param = pickle.load(open(model_file, 'rb'))\n",
    "        except: policy_param = pickle.load(open(model_file, 'rb'), encoding='bytes')\n",
    "            \n",
    "        best_policy = PolicyValueNetNumpy(width, height, policy_param)\n",
    "        mcts_player = MCTSPlayer(best_policy.policy_value_fn, c_puct=5, n_playout=400)  # n_playout 값이 커지면 성능이 좋아짐\n",
    "\n",
    "        # pure MCTS를 사용하려면 아래 줄을 사용 (더 큰 n_playout 값으로도 성능이 약함.)\n",
    "        # mcts_player = MCTS_Pure(c_puct=5, n_playout=1000)\n",
    "\n",
    "        # human player, input your move in the format: 2,3\n",
    "        human = Human()\n",
    "\n",
    "        # set start_player=0 for human first\n",
    "        game.start_play(human, mcts_player, start_player=1, is_shown=1)\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\n\\rquit')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "# some utility functions\n",
    "def softmax(x):\n",
    "    probs = np.exp(x - np.max(x))\n",
    "    probs /= np.sum(probs)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def relu(X):\n",
    "    out = np.maximum(X, 0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def conv_forward(X, W, b, stride=1, padding=1):\n",
    "    n_filters, d_filter, h_filter, w_filter = W.shape\n",
    "    # theano conv2d flips the filters (rotate 180 degree) first\n",
    "    # while doing the calculation\n",
    "    W = W[:, :, ::-1, ::-1]\n",
    "    n_x, d_x, h_x, w_x = X.shape\n",
    "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
    "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
    "    h_out, w_out = int(h_out), int(w_out)\n",
    "    X_col = im2col_indices(X, h_filter, w_filter,\n",
    "                           padding=padding, stride=stride)\n",
    "    W_col = W.reshape(n_filters, -1)\n",
    "    out = (np.dot(W_col, X_col).T + b).T\n",
    "    out = out.reshape(n_filters, h_out, w_out, n_x)\n",
    "    out = out.transpose(3, 0, 1, 2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fc_forward(X, W, b):\n",
    "    out = np.dot(X, W) + b\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_im2col_indices(x_shape, field_height,\n",
    "                       field_width, padding=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * padding - field_height) % stride == 0\n",
    "    assert (W + 2 * padding - field_height) % stride == 0\n",
    "    out_height = int((H + 2 * padding - field_height) / stride + 1)\n",
    "    out_width = int((W + 2 * padding - field_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k.astype(int), i.astype(int), j.astype(int))\n",
    "\n",
    "\n",
    "def im2col_indices(x, field_height, field_width, padding=1, stride=1):\n",
    "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
    "\n",
    "    k, i, j = get_im2col_indices(x.shape, field_height,\n",
    "                                 field_width, padding, stride)\n",
    "\n",
    "    cols = x_padded[:, k, i, j]\n",
    "    C = x.shape[1]\n",
    "    cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
    "    return cols\n",
    "\n",
    "\n",
    "class PolicyValueNetNumpy():\n",
    "    \"\"\"policy-value network in numpy \"\"\"\n",
    "    def __init__(self, board_width, board_height, net_params):\n",
    "        self.board_width = board_width\n",
    "        self.board_height = board_height\n",
    "        self.params = net_params\n",
    "\n",
    "    def policy_value_fn(self, board):\n",
    "        \"\"\"\n",
    "        input: board\n",
    "        output: a list of (action, probability) tuples for each available\n",
    "        action and the score of the board state\n",
    "        \"\"\"\n",
    "        legal_positions = board.availables\n",
    "        current_state = board.current_state()\n",
    "\n",
    "        X = current_state.reshape(-1, 4, self.board_width, self.board_height)\n",
    "        # first 3 conv layers with ReLu nonlinearity\n",
    "        for i in [0, 2, 4]:\n",
    "            X = relu(conv_forward(X, self.params[i], self.params[i+1]))\n",
    "        # policy head\n",
    "        X_p = relu(conv_forward(X, self.params[6], self.params[7], padding=0))\n",
    "        X_p = fc_forward(X_p.flatten(), self.params[8], self.params[9])\n",
    "        act_probs = softmax(X_p)\n",
    "        # value head\n",
    "        X_v = relu(conv_forward(X, self.params[10],\n",
    "                                self.params[11], padding=0))\n",
    "        X_v = relu(fc_forward(X_v.flatten(), self.params[12], self.params[13]))\n",
    "        value = np.tanh(fc_forward(X_v, self.params[14], self.params[15]))[0]\n",
    "        act_probs = zip(legal_positions, act_probs.flatten()[legal_positions])\n",
    "        return act_probs, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
